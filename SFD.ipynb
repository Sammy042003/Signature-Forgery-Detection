{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.26.0-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (1.16.3)\n",
      "Collecting networkx>=3.0 (from scikit-image)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (12.1.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.12.20-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from scikit-image) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.26.0-cp313-cp313-win_amd64.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 38.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 36.1 MB/s  0:00:00\n",
      "Downloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 29.8 MB/s  0:00:00\n",
      "Downloading tifffile-2025.12.20-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   -------- ------------------------------- 1/5 [networkx]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [imageio]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [scikit-image]\n",
      "   ---------------------------------------- 5/5 [scikit-image]\n",
      "\n",
      "Successfully installed imageio-2.37.2 lazy-loader-0.4 networkx-3.6.1 scikit-image-0.26.0 tifffile-2025.12.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
      "Collecting markupsafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 7.1/332.0 MB 36.8 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 15.2/332.0 MB 37.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 22.3/332.0 MB 36.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 27.8/332.0 MB 34.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 32.2/332.0 MB 31.8 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 38.0/332.0 MB 30.9 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 44.0/332.0 MB 30.7 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 49.8/332.0 MB 30.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 55.8/332.0 MB 30.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 61.3/332.0 MB 30.2 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 68.4/332.0 MB 30.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 73.7/332.0 MB 30.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 79.2/332.0 MB 29.8 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 84.9/332.0 MB 29.7 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 90.2/332.0 MB 29.5 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 93.1/332.0 MB 28.7 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 94.4/332.0 MB 27.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 95.7/332.0 MB 26.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 97.5/332.0 MB 25.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 99.9/332.0 MB 24.5 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 102.2/332.0 MB 24.0 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 104.6/332.0 MB 23.3 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 107.2/332.0 MB 22.8 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 110.6/332.0 MB 22.5 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 113.0/332.0 MB 22.0 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 115.9/332.0 MB 21.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 119.3/332.0 MB 21.5 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 123.2/332.0 MB 21.4 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 127.1/332.0 MB 21.3 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 130.0/332.0 MB 21.1 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 132.1/332.0 MB 20.7 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 134.0/332.0 MB 20.4 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 136.6/332.0 MB 20.1 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 139.7/332.0 MB 19.9 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 142.9/332.0 MB 19.8 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 146.3/332.0 MB 19.7 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 149.9/332.0 MB 19.7 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 154.1/332.0 MB 19.7 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 158.1/332.0 MB 19.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 162.8/332.0 MB 19.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 168.0/332.0 MB 20.0 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 172.8/332.0 MB 20.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 177.7/332.0 MB 20.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 183.0/332.0 MB 20.3 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 189.0/332.0 MB 20.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 194.8/332.0 MB 20.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 200.3/332.0 MB 20.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 205.0/332.0 MB 20.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 208.9/332.0 MB 20.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 212.9/332.0 MB 20.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 217.3/332.0 MB 20.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 221.0/332.0 MB 20.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 222.3/332.0 MB 20.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 223.6/332.0 MB 20.2 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 225.2/332.0 MB 19.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 226.8/332.0 MB 19.8 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 228.1/332.0 MB 19.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 229.6/332.0 MB 19.3 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 231.7/332.0 MB 19.2 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 234.4/332.0 MB 19.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 237.0/332.0 MB 18.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 240.4/332.0 MB 18.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 243.8/332.0 MB 18.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 247.7/332.0 MB 18.9 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 252.2/332.0 MB 18.9 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 256.9/332.0 MB 19.0 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 261.9/332.0 MB 19.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 265.8/332.0 MB 18.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 270.8/332.0 MB 18.8 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 276.6/332.0 MB 18.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 280.2/332.0 MB 18.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 282.9/332.0 MB 18.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 285.7/332.0 MB 18.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 287.8/332.0 MB 18.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 290.5/332.0 MB 18.0 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 293.3/332.0 MB 17.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 295.4/332.0 MB 17.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 297.8/332.0 MB 17.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 299.6/332.0 MB 17.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 302.3/332.0 MB 17.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 306.2/332.0 MB 17.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 310.1/332.0 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 313.5/332.0 MB 17.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 316.7/332.0 MB 17.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 320.1/332.0 MB 16.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  324.0/332.0 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  328.5/332.0 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 16.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 16.3 MB/s  0:00:18\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 15.1 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 21.0 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 14.9 MB/s  0:00:00\n",
      "Downloading keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 21.0 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 5.0/26.4 MB 23.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.2/26.4 MB 24.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 24.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.4/26.4 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 24.4 MB/s  0:00:01\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-win_amd64.whl (60 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, setuptools, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markupsafe, markdown, h5py, grpcio, google_pasta, gast, absl-py, werkzeug, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/27 [libclang]\n",
      "   - --------------------------------------  1/27 [libclang]\n",
      "   ----- ----------------------------------  4/27 [wheel]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ---------- -----------------------------  7/27 [setuptools]\n",
      "   ----------- ----------------------------  8/27 [protobuf]\n",
      "   ----------- ----------------------------  8/27 [protobuf]\n",
      "   ------------- --------------------------  9/27 [optree]\n",
      "   -------------- ------------------------- 10/27 [opt_einsum]\n",
      "   -------------------- ------------------- 14/27 [markdown]\n",
      "   ---------------------- ----------------- 15/27 [h5py]\n",
      "   ---------------------- ----------------- 15/27 [h5py]\n",
      "   ----------------------- ---------------- 16/27 [grpcio]\n",
      "   ----------------------- ---------------- 16/27 [grpcio]\n",
      "   ------------------------- -------------- 17/27 [google_pasta]\n",
      "   ---------------------------- ----------- 19/27 [absl-py]\n",
      "   ----------------------------- ---------- 20/27 [werkzeug]\n",
      "   ------------------------------- -------- 21/27 [markdown-it-py]\n",
      "   ------------------------------- -------- 21/27 [markdown-it-py]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ---------------------------------- ----- 23/27 [tensorboard]\n",
      "   ----------------------------------- ---- 24/27 [rich]\n",
      "   ----------------------------------- ---- 24/27 [rich]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   ------------------------------------- -- 25/27 [keras]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   -------------------------------------- - 26/27 [tensorflow]\n",
      "   ---------------------------------------- 27/27 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.13.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.4 rich-14.2.0 setuptools-80.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 werkzeug-3.1.5 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\4278386520.py:20: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Necessary Libraries needed\n",
    "import numpy as np     #  for numerical operations\n",
    "import os              #  for interacting with the operating system\n",
    "import matplotlib      #  for plotting and visualizations\n",
    "import matplotlib.pyplot as plt   #  for creating plots\n",
    "import matplotlib.image as mpimg  #   for image-related operations\n",
    "import matplotlib.cm as cm   #  \n",
    "from scipy import ndimage   #  for image processing\n",
    "from skimage.measure import regionprops   #  for region properties extraction\n",
    "from skimage import io   #  for image input/output operations\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\n",
    "import tensorflow as tf   #  for building and training machine learning models\n",
    "import pandas as pd   #  for data manipulation\n",
    "import numpy as np\n",
    "from time import time   #  for time-related functions\n",
    "import keras   #  for building neural networks\n",
    "from tensorflow.python.framework import ops  \n",
    "import tensorflow.compat.v1 as tf   #   #  for backward compatibility with TensorFlow 1.x\n",
    "\n",
    "tf.disable_v2_behavior()   #   to disable TensorFlow 2.x behav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\1785656828.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  genuine_image_paths = \"D:\\Signature forgery detection\\real\"\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\1785656828.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  forged_image_paths = \"D:\\Signature forgery detection\\forged\"\n"
     ]
    }
   ],
   "source": [
    "genuine_image_paths = \"D:\\Signature forgery detection\\real\"\n",
    "forged_image_paths = \"D:\\Signature forgery detection\\forged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function converts a given RGB image to grayscale by taking the average of the RGB channels.\n",
    "\n",
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function converts a grayscale image to binary using Otsu's thresholding method. It also applies Gaussian blur to remove noise.\n",
    "\n",
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function preprocesses the image by converting it to grayscale and then to binary. It also displays intermediate results if display is set to True.\n",
    "\n",
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function calculates the ratio of white pixels to the total number of pixels in a binary image.\n",
    "\n",
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function calculates the centroid of a binary image\n",
    "\n",
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function calculates the eccentricity and solidity of a binary image using region properties.\n",
    "\n",
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function calculates skewness and kurtosis along both the x and y axes for a binary image.\n",
    "\n",
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # cols value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function combines all the previously defined feature extraction functions to extract features from a signature image.\n",
    "\n",
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function extracts features and prepares them in a format suitable for saving to a CSV file.\n",
    "\n",
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This function creates CSV files for storing features extracted from genuine and forged signature images. It loops through the directories containing these images, extracts features, and writes them to CSV files.\n",
    "\n",
    "import os\n",
    "\n",
    "def makeCSV():\n",
    "    if not(os.path.exists(r'D:\\Signature forgery detection\\Features')):\n",
    "        os.mkdir(r'D:\\Signature forgery detection\\Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists(r'D:\\Signature forgery detection\\Features\\Training')):\n",
    "        os.mkdir(r'D:\\Signature forgery detection\\Features\\Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists(r'D:\\Signature forgery detection\\Features\\Testing')):\n",
    "        os.mkdir(r'D:\\Signature forgery detection\\Features\\Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    # genuine signatures path\n",
    "    gpath = r'D:\\Signature forgery detection\\real'\n",
    "    # forged signatures path\n",
    "    fpath = r'D:\\Signature forgery detection\\forged'\n",
    "    for person in range(1,13):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        \n",
    "        with open(r'D:\\Signature forgery detection\\Features\\Training/training_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Training set\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n",
    "        \n",
    "        with open(r'D:\\Signature forgery detection\\Features\\Testing/testing_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Testing set\n",
    "            for i in range(3, 5):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(3,5):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 001\n",
      "Saving features for person id- 002\n",
      "Saving features for person id- 003\n",
      "Saving features for person id- 004\n",
      "Saving features for person id- 005\n",
      "Saving features for person id- 006\n",
      "Saving features for person id- 007\n",
      "Saving features for person id- 008\n",
      "Saving features for person id- 009\n",
      "Saving features for person id- 010\n",
      "Saving features for person id- 011\n",
      "Saving features for person id- 012\n"
     ]
    }
   ],
   "source": [
    "makeCSV()   #  generate and save the CSV files containing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\3804206035.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  if not(os.path.exists('D:\\Signature forgery detection/TestFeatures')):\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\3804206035.py:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  os.mkdir('D:\\Signature forgery detection/TestFeatures')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_27804\\3804206035.py:7: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  with open('D:\\Signature forgery detection\\TestFeatures/testcsv.csv', 'w') as handle:\n"
     ]
    }
   ],
   "source": [
    "# This function appears to be for testing a single image. It extracts features from the image and saves them to a CSV file.  \n",
    "\n",
    "def testing(path):\n",
    "    feature = getCSVFeatures(path)\n",
    "    if not(os.path.exists('D:\\Signature forgery detection/TestFeatures')):\n",
    "        os.mkdir('D:\\Signature forgery detection/TestFeatures')\n",
    "    with open('D:\\Signature forgery detection\\TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine Image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  These lines set up variables related to the training and testing of the model. It prompts the user to input a person's ID and the path of a test signature image.\n",
    "\n",
    "n_input = 9\n",
    "train_person_id = input(\"Enter person's id : \")\n",
    "test_image_path = input(\"Enter path of signature image : \")\n",
    "train_path = 'D:\\\\Signature forgery detection\\\\Features\\\\Training/training_'+train_person_id+'.csv'\n",
    "testing(test_image_path)\n",
    "test_path = 'D:\\\\Signature forgery detection\\\\TestFeatures/testcsv.csv'\n",
    "\n",
    "#  This function reads data from CSV files containing training and testing data. It converts the data into appropriate formats for training and testing the TensorFlow model.\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "ops.reset_default_graph()   #  This line resets the TensorFlow default graph, necessary if re-running the code multiple times in the same session.\n",
    "\n",
    "# These lines set up parameters for the neural network model: learning rate, number of training epochs, number of neurons in each hidden layer, and number of output classes.\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "n_hidden_3 = 30 # 3rd layer\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])   #  These lines define TensorFlow placeholders for input data (X) and labels (Y).\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "#             # Display logs per epoch step\n",
    "#             if epoch % 999 == 0:\n",
    "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "#         print(\"Optimization Finished!\")\n",
    "        \n",
    "        # Finding accuracies\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "#         print(\"Accuracy for train:\", accuracy1)\n",
    "#         print(\"Accuracy for test:\", accuracy2)\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image')\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image')\n",
    "                return False\n",
    "\n",
    "\n",
    "def trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    n_hidden_2 = 7 # 2nd layer number of neurons\n",
    "    n_hidden_3 = 30 # 3rd layer\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = 10\n",
    "    for i in range(1,n+1):\n",
    "        if display:\n",
    "            print(\"Running for Person id\",i)\n",
    "        temp = ('0'+str(i))[-2:]\n",
    "        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print(\"Training average-\", train_avg/n)\n",
    "        print(\"Testing average-\", test_avg/n)\n",
    "        print(\"Time taken-\", time()-start)\n",
    "    return train_avg/n, test_avg/n, (time()-start)/n\n",
    "\n",
    "\n",
    "evaluate(train_path, test_path, type2=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
